# 网络编程入门

## 计算机网络基础

计算机网络是独立自主的计算机互联而成的系统的总称，组件计算机网络最主要的目的是实现多台计算机之间的通信和资源共享。

### OSI七层模型

OSI模型的目的是规范不同系统的互联标准，使两个不同的系统能够较容易的通信，而不需要改变底层的硬件或软件的逻辑。
OSI模型的优点：

+ 将网络的通信过程划分为小且简单的部件，因此有助于各个部件的开发、设计和故障排除
+ 通过网络组件的标准化，允许多个供应商进行开发
+ 通过定义在模型的每一层实现什么功能，鼓励产业的标准化
+ 允许各类型的网络硬件和软件之间相互通信
+ 防止对某一层所做的改动影响到其他层
  
OSI七层模型按照功能划分为七层，分别是：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。
他们的功能如下图所示：
![OSI七层模型](../img/OSI.png)
特点：

+ OSI模型每层都有自己的功能
+ 层与层之间相互独立又相互依靠
+ 上层依赖于下层，下层服务于上层

### TCP/IP四层模型

实现网络通信的基础是网络通信协议，这些协议通常是由IETF指定的。网络协议的三要素是：语法、语义和时序。语法是指数据与控制信息的结构或格式。语义是指需要发出何种控制信息以及完成何种动作。时序是指事件发生的顺序。构成我们今天使用的Internet的基础的是TCP/IP协议族，所谓协议族就是一系列的协议及其构成的通信模型，我们通常也把这套东西成为TCP/IP模型。该模型将我们使用的网络从逻辑上分解为四个层次，分别是：网络接口层、网络层、传输层、应用层。
![TCP/IP四层模型](../img/TCP-IP-model.png)
IP通常被反以为网际协议，他服务于网络层，主要实现了寻址和路由的功能。介入网络的每一台主机都需要有自己的IP地址，IP地址就是主机在计算机网络上的身份标识。当然由于IPV4地址的匮乏，我们平常在家里、办公室以及其他可以介入网络的公共区域上网时获得的IP地址并不是全球唯一的IP地址，而是局域网(LAN)中的内部IP地址，通过网络地址转换(NAT)技术，我们可以将内部IP地址转换为全球唯一的IP地址，从而实现了我们的上网需求。计算机网络上游大量被我们成为“路由器”的网络中继设备，它们会存储转化我们发送到网络上的数据分组，让源头发出的数据能够最终找到转送目的地的通路，这项功能就是所谓的路由。
IP协议负责将数据从一台计算机通过网络发送到另一台计算机。数据被分割成一小块一小块，然后通过IP包发送出去。由于互联网链路复杂，两台计算机之间经常有多天线路，因此，路由器就负责把一个IP包转发出去。IP包的特点是按块发送，途径多个路由，但不保证能到达，也不保证顺序到达。
TCP全称传输控制协议，它是基于IP提供的寻址和路由服务而建立起来的负责实现端到端可靠传输的协议，之所以将TCP成为可靠的传输协议是因为TCP向调用者承诺了三件事：

1. 数据不传丢不传错(利用握手、校验和重传机制可以实现)
2. 流量控制(通过滑动窗口匹配数据发送者和接受者之间的传输速度)
3. 拥塞控制(RTT时间以及对滑动窗口的控制环节网络拥堵)

TCP协议是建立在IP协议上的。TCP协议负责在两台计算机之间建立可靠连接，保证数据包按顺序到达。TCP协议会通过我手机案例，然后，对每个IP包编号，确保对方按顺序收到，如果包丢了，就自动重发。
一个TCP报文除了包含要传输的数据外，还包含源IP地址和目标IP地址，源端口和目标端口。端口有什么用呢？在两台计算机通信时，只发IP地址是不够的，因为同一台计算机上跑着多个网络程序。一个TCP报文来了之后，到底是交给浏览器还是交给邮件程序，就需要端口号来区分。每个网络程序都向操作系统申请唯一的端口号，这样，两个进程在两台计算机之间建立网络连接就需要各自的IP地址和各自的端口号。

### HTTP协议入门

#### HTTP/0.9

HTTP时基于TCP/IP协议的应用层协议。他不涉及数据包（packet）传输，主要规定了客户端和服务器之间的通信格式，默认端口号是80。最早版本是1991年发布的0.9版，只有一个命令GET。

```html
GET/index.html
```

上面命令表示，TCP连接建立后，客户端向服务器请求（request）网页index.html。协议规定，服务器只能回应HTML格式的字符串，不能回应别的格式。服务器发送完毕，就关闭TCP连接。

#### HTTP/1.0

1996年5月，HTTP/1.0版本发布。这个版本新增了很多命令，比如`HEAD`命令用于获取报文头部，`POST`命令用于提交表单数据。HTTP请求和回应的格式也变了，详细内容请参考[HTTP/1.0协议](https://www.w3.org/Protocols/HTTP/1.0/spec.html)。除了数据部分，每次通信都必须包括头信息，用来描述一些元数据。其他的新增功能还包括状态码，多字符集支持、多部分发送、权限、缓存、内容编码等。
西面是一个1.0版本的HTTP请求的例子。

```html
GET / HTTP/1.0
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)
Accept: */*
```

服务器的回应如下：

```html
HTTP/1.0 200 OK 
Content-Type: text/plain
Content-Length: 137582
Expires: Thu, 05 Dec 1997 16:00:00 GMT
Last-Modified: Wed, 5 August 1996 15:55:28 GMT
Server: Apache 0.84

<html>
  <body>Hello World</body>
</html>
```

回应的格式是“头信息+一个空行(\r\n)+数据”。其中，第一行是"协议版本+状态码+状态描述”。
关于字符编码，1.0版规定，头信息必须是ASCII码，后面的数据可以使任何格式。因此，服务器回应的时候，必须告诉客户端，数据是什么格式，这就是Content-Type字段的作用。
下面是一些常见的Content-Type字段的值。

+ text/plain
+ text/html
+ text/css
+ image/jpeg
+ image/png
+ image/svg+xml
+ audio/mp4
+ video/mp4
+ application/javascript
+ application/pdf
+ application/zip
+ application/atom+xml

这些数据类型总称为`MIME type`，每个值包括一级类型和二级类型，之间用斜杠分割。`MIME type`还可以在尾部使用分号，添加参数。比如，`Content-Type: text/html;charset=utf-8`上面类型表明，发送的是网页，而且编码是utf-8.
客户端请求的时候，可以使用`Accept`字段表明自己可以接受那些数据格式。`Accept:*/*`。上面代码中，客户端生命自己可以接受任何格式的数据。

`MIME type`不仅用在HTTP协议，还可以用在其他地方，比如HTML网页。

```html
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<!-- 等同于 -->
<meta charset="utf-8" /> 
```

由于发送的数据可以使任何格式，因此可以把数据压缩后再发送。`Content-Encoding`字段说明数据压缩的方法。比如，`Content-Encoding: gzip`表示数据采用gzip压缩。常用的压缩方法有以下几种。

+ Content-Encoding: gzip
+ Content-Encoding: compress
+ Content-Encoding: deflate
  
客户端在请求时，用`Accept-Encoding`字段说明自己可以接受哪些压缩方法。

```html
Accept-Encoding: gzip, deflate
```

##### 缺点

HTTP/1.0协议的主要缺点是，每个TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。

TCP连接的新建崇本核稿，因为需要客户端和服务器三次握手，并且开始时发送速率较慢（slow start）。如果每个资源都建立一个新连接，会浪费很多时间。

为了解决这个问题,有些浏览器在请求时，用了一个非标准的`Connection`字段。

```html
CONnection: keep-alive
```

这个字段要求服务器不要关闭TCP连接，一边请求复用。服务器同样回应这个字段。

```html
Connection: keep-alive
```

一个可以复用的TCP连接就建立了。，知道客户端或服务器主动关闭连接。但是，这不是标准字段，不同实现的行为可能不一致，因此不是根本的解决办法。

#### HTTP/1.1

1997年1月，HTTP/1.1版本发布，只比1.0版本完了半年。他进一步完善了HTTP协议，一直用到了20年后的今天，直到现在还是最流行的版本。1.1版最大的变化，就是引入了持久丽娜姐，即连接默认不关闭，可以被多个请求复用，不用声明`Connection:keep-alive`。
客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接。不过，规范的做法是，客户端在最后一个请求时，发送`Connection:close`，明确要求服务器关闭TCP连接。目前，对于同一个域名，大多数浏览器允许同时建立6个持久连接。
1.1版还引入了管道机制，即在同一个TCP连接里面，先发送A请求，然后等待服务器做出相应，收到后再发出B请求。管道机制则是允许浏览器同时发送A请求和B请求，但是服务器还是按照顺序，先回应A请求，完成后再回应B请求。
一个TCP连接现在可以传送多个回应，势必就要有一种机制，区分数据包是属于那一个回应的。这就是`Content-Length`字段的作用，声明本次回应的数据长度。
`Content-Length:3495`
上面的代码告诉浏览器，本次回应的长度是3495个字节，后面的字节就属于下一个回应了。在1.0版中，`Content-Length`字段是可选的，因为浏览器发现服务器关闭了TCP连接，就表明收到的数据包已经全了，但是在1.1版中，它是HTTP协议必须遵守的。
使用`Content-Length`字段的前提是，服务器发送回应之前，必须知道回应的数据长度。这就要求服务器在发送回应之前，要先将回应的所有数据包装好，才能知道数据的长度。这就导致了两个问题：一是服务器不能是实时生成回应，而是要事先写好；二是服务器只能一次性发送回应，不能分段发送。更好的处理方式是，产生一块数据，就发送一块数据，采用“流模式”求带“缓存模式”。
因此，1.1版本规定可以不适用`Content-Length`字段，而是用分块传输编码。只要请求或回应的头信息由`Transfer-Encoding`字段，就表明回应将有数量未定的数据块组成。

```http
Transfer-Encoding: chunked
```

每个非空的数据块之前，都必须有一个头信息，标明数据块的长度。头信息长度是个十六进制的数值，回应的最后一个数据块长度必须是0，对应的数据没有内容。下面是一个例子。

```http
HTTp/1.1 200 OK
Content-Type: text/plain
Transfer-Encoding: chunked
25
This is the data in the first chunk

1C
and this is the second one

3
con

8
sequence

0

```

1.1版还新增了许多动词用法：`PUT`、`PATCH`、`HEAD`、`OPTIONS`、`DELETE`。
另外，客户端请求的头部信息新增了`Host`字段，用来指定服务器的域名。

```http
Host: www.example.com
```

虽然1.1版允许复用TCP连接，但是同一个TCP连接里面，所有的数据通信是按次序进行的。服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着。这称为“队头堵塞”（Head-of-line blocking）。为了避免这个问题，只有两种方法：一是减少请求数，二是同时多开持久连接。这倒是了很多网页优化技巧。

#### HTTP/2

HTTP/1.1 版的头信息肯定是文本（ASCII编码），数据体可以是文本，也可以是二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"（frame）：头信息帧和数据帧。

二进制协议的一个好处是，可以定义额外的帧。HTTP/2 定义了近十种帧，为将来的高级应用打好了基础。如果使用文本实现这种功能，解析数据将会变得非常麻烦，二进制解析则方便得多。

HTTP/2 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了"队头堵塞"。
举例来说，在一个TCP连接里面，服务器同时收到了A请求和B请求，于是先回应A请求，结果发现处理过程非常耗时，于是就发送A请求已经处理好的部分， 接着回应B请求，完成后，再发送A请求剩下的部分。
这样双向的、实时的通信，就叫做多工（Multiplexing）。
HTTP 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，比如Cookie和User Agent，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。

HTTP/2 对这一点做了优化，引入了头信息压缩机制（header compression）。一方面，头信息使用gzip或compress压缩后再发送；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。
HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。

常见场景是客户端请求一个网页，这个网页里面包含很多静态资源。正常情况下，客户端必须收到网页后，解析HTML源码，发现有静态资源，再发出静态资源请求。其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了。

以上为Python爬虫预备知识

## TCP编程

Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。

### TCP客户端

大多数链接都是可靠的TCP连接。创建TCP连接时，主动发起连接的叫客户端，被动响应链接的叫服务器。
举一个例子，当我们在浏览器中访问新浪网时，我们自己的计算机就是客户端，浏览器会主动向新浪的服务器发起连接。如果一切顺利，新浪的服务器接受了我们的连接，一个TCP连接就建立起来的，后面的通信就是发送网页内容了。所以，我们要创建一个基于TCP连接的Socket，可以这样做：

```python
import socket
import ssl

# 创建一个socket:
s = ssl.wrap_socket(socket.socket())
# 建立连接:
s.connect(('www.sina.com.cn', 443))
s.send(b'GET / HTTP/1.1\r\nHost: www.sina.com.cn\r\nConnection: close\r\n\r\n')
buffer = []
while True:
    # 每次最多接收1k字节:
    d = s.recv(1024)
    if d:
        buffer.append(d)
    else:
        break
data = b''.join(buffer)
s.close()
header, html = data.split(b'\r\n\r\n', 1)
print(header.decode('utf-8'))
# 把接收的数据写入文件:
with open('sina.html', 'wb') as f:
    f.write(html)

```

创建`Socket`时，`AF_INET`指定使用IPv4协议，如果要用更先进的IPv6，就指定为`AF_INET6`。SOCK_STREAM指定使用面向流的TCP协议。
客户端要主动发起TCP连接，必须知道服务器的IP地址和端口号。

TCP连接建立的是双向通道，双方都可以给对方发数据。但是谁先发谁后发，怎么协调，要根据具体的协议来决定。例如，HTTP协议规定客户端必须先发请求给服务器，服务器收到后才发数据给客户端。发送的文本格式必须符合HTTP标准。

接受数据室，调用`recv(max)`方法，一次最多接收指定的字节数，因此，在一个while循环中反复接收，直到recv()返回空数据，表示接收完毕，退出循环。

当我们接收完数据后，调用`close()`方法关闭`Socket`，这样，一次完整的网络通信就结束了。

### TCP 服务器

和客户端编程相比，服务器编程就要复杂一些。

服务器进程首先要绑定一个端口并监听来自其他客户端的连接。如果某个客户端连接过来了，服务器就与该客户端建立Socket连接，随后的通信就靠这个Socket连接了。

所以，服务器会打开固定端口（比如80）监听，每来一个客户端连接，就创建该Socket连接。由于服务器会有大量来自客户端的连接，所以，服务器要能够区分一个Socket连接是和哪个客户端绑定的。一个Socket依赖4项：服务器地址、服务器端口、客户端地址、客户端端口来唯一确定一个Socket。

但是服务器还需要同时响应多个客户端的请求，所以，每个连接都需要一个新的进程或者新的线程来处理，否则，服务器一次就只能服务一个客户端了。
我们来编写一个简单的服务器程序，它接收客户端连接，把客户端发过来的字符串加上Hello再发回去。

```python
import socket
import threading
import time


def tcplink(sock, addr):
    print('Accept new connection from %s:%s' % addr)
    sock.send(b'Welcome!')
    while True:
        data = sock.recv(1024)
        time.sleep(1)
        if not data or data.decode('utf-8') == 'exit':
            break
        sock.send(('Hello,%s!' % data.decode('utf-8')).encode('utf-8'))
    sock.close()
    print('Connection from %s:%s' % addr)


s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

s.bind(('127.0.0.1', 9999))
s.listen(5)
print('Waiting foe connection')
while True:
    sock, addr = s.accept()
    t = threading.Thread(target=tcplink, args=(sock, addr))
    t.start()

```

然后，我们要绑定监听的地址和端口。服务器可能有多块网卡，可以绑定到某一块网卡的IP地址上，也可以用0.0.0.0绑定到所有的网络地址，还可以用127.0.0.1绑定到本机地址。127.0.0.1是一个特殊的IP地址，表示本机地址，如果绑定到这个地址，客户端必须同时在本机运行才能连接，也就是说，外部的计算机无法连接进来。

端口号需要预先指定。因为我们写的这个服务不是标准服务，所以用9999这个端口号。请注意，小于1024的端口号必须要有管理员权限才能绑定.
紧接着，调用listen()方法开始监听端口，传入的参数指定等待连接的最大数量，接下来，服务器程序通过一个永久循环来接受来自客户端的连接，accept()会等待并返回一个客户端的连接，每个连接都必须创建新线程（或进程）来处理，否则，单线程在处理连接的过程中，无法接受其他客户端的连接。
要测试这个服务器程序，我们还需要编写一个客户端程序：

```python
import socket

s = socket.socket(socket.AF_INET,socket.SOCK_STREAM)
s.connect(('127.0.0.1',9999))
print(s.recv(1024).decode('utf-8'))
for data in [b'Michael', b'Tracy',b'Sarah']:
    s.send(data)
    print(s.recv(1024).decode('utf-8'))
s.send(b'exit')
s.close()
```

### UDP编程

TCP是建立可靠连接，并且通信双方都可以以流的形式发送数据。相对TCP，UDP则是面向无连接的协议。

使用UDP协议时，不需要建立连接，只需要知道对方的IP地址和端口号，就可以直接发数据包。但是，能不能到达就不知道了。

虽然用UDP传输数据不可靠，但它的优点是和TCP比，速度快，对于不要求可靠到达的数据，就可以使用UDP协议。

我们来看看如何通过UDP协议传输数据。和TCP类似，使用UDP的通信双方也分为客户端和服务器。

```python
import socket

s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
s.bind(('127.0.0.1', 9999))
print('Bind UDP on 9999...')
while True:
    data, addr = s.recvfrom(1024)
    print('Received from %s:%s.'% addr)
    s.sendto(b'Hello, %s'%data, addr)

```

```python
import socket

s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
for data in [b'Michael', b'Tracy', b'Sarah']:
    s.sendto(data, ('127.0.0.1', 9999))
    print(s.recv(1024).decode('utf-8'))
s.close()
```
## JSON

JSON是一种轻量级的数据交换格式，在Python3中可以利用`json`对JSON格式
## requests库

requests是一个基于HTTP协议来使用网络的第三库，可以避免安全缺陷、冗余代码以及“重复发明轮子”。
下面是一个通过requests库来获取经典电影语句的例子：

```python
from time import time
from threading import Thread

import requests

class DownloadHanlder(Thread):

    def __init__(self, url):
        super.__init__()
        self.url = url

    def run(self):
        filename = self.url[self.url.rfind('/')+1:]
        resp = requests.get(self.url)
        with open('./resource/'+filename,'wb') as f:
            f.write(resp.content)

def main():
    resp = requests.get('https://apis.tianapi.com/dialogue/index?key=80182ab7cebbcf0a013a63d8db2281f2')
    data_model = resp.json()
    # print(data_model)
    print('%s:%s'%(data_model['result']['source'],data_model['result']['dialogue']))
    # for mm_dict in data_model['newslist']:
    #     url = mm_dict['picUrl']
    #     DownloadHanlder(url).start()

if __name__ == '__main__':
    for i in range(0, 10):
        main()
```
